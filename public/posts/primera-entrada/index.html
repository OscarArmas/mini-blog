<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="How we architected a high-throughput prediction service handling 200&#43; RPS with &lt;100ms latency using Go and Triton.">
    <meta name="author" content="Oscar Armas">
    
    <title>Low-Latency Inference at Scale | Oscar Armas | Staff ML Engineer</title>
    
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Space+Mono:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
    
    
    <link rel="stylesheet" href="/css/main.css">
    
    
    
</head>
<body>
    
    <header class="site-header">
        <nav class="navbar">
            <a href="/" class="logo">
                Oscar Armas | Staff ML Engineer
            </a>
            <ul class="nav-menu">
                <li><a href="/">Inicio</a></li>
                <li><a href="/posts">Posts</a></li>
                
            </ul>
            <button class="menu-toggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </nav>
    </header>

    
    <main class="stream-container">
        
<header>
    <h1>Low-Latency Inference at Scale</h1>
    <div class="post-meta" style="margin-top: 1rem; margin-bottom: 2rem;">
        2024-01-15
        
        • Oscar Armas
        
        
        • 1 min de lectura
        
    </div>
    
    <div class="post-tags" style="margin-bottom: 2rem;">
        
        <span class="tag">#mlops</span>
        
        <span class="tag">#realtime</span>
        
        <span class="tag">#golang</span>
        
    </div>
    
</header>

<section>
    <div class="post-content">
        <p>This is a sample post demonstrating the &ldquo;Real-Time&rdquo; category style.</p>
<h2 id="the-challenge">The Challenge</h2>
<p>Deploying heavy transformer models for real-time fraud detection requires a robust infrastructure. We needed to serve predictions in under 100ms to avoid blocking the user checkout flow.</p>
<h3 id="architecture-choices">Architecture Choices</h3>
<p>We moved from a Python-based Flask service to a high-performance Go gateway communicating with NVIDIA Triton Inference Server via gRPC.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-go" data-lang="go"><span style="display:flex;"><span><span style="color:#66d9ef">func</span> (<span style="color:#a6e22e">s</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">Server</span>) <span style="color:#a6e22e">Predict</span>(<span style="color:#a6e22e">ctx</span> <span style="color:#a6e22e">context</span>.<span style="color:#a6e22e">Context</span>, <span style="color:#a6e22e">req</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Request</span>) (<span style="color:#f92672">*</span><span style="color:#a6e22e">pb</span>.<span style="color:#a6e22e">Response</span>, <span style="color:#66d9ef">error</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// High-performance gRPC call to Triton</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">resp</span>, <span style="color:#a6e22e">err</span> <span style="color:#f92672">:=</span> <span style="color:#a6e22e">s</span>.<span style="color:#a6e22e">tritonClient</span>.<span style="color:#a6e22e">Infer</span>(<span style="color:#a6e22e">ctx</span>, <span style="color:#a6e22e">modelName</span>, <span style="color:#a6e22e">inputs</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> <span style="color:#a6e22e">err</span> <span style="color:#f92672">!=</span> <span style="color:#66d9ef">nil</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">nil</span>, <span style="color:#a6e22e">fmt</span>.<span style="color:#a6e22e">Errorf</span>(<span style="color:#e6db74">&#34;inference failed: %w&#34;</span>, <span style="color:#a6e22e">err</span>)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#a6e22e">processResponse</span>(<span style="color:#a6e22e">resp</span>), <span style="color:#66d9ef">nil</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="results">Results</h2>
<ul>
<li><strong>Latency</strong>: Reduced p99 from 450ms to 85ms.</li>
<li><strong>Throughput</strong>: Increased capacity by 4x with the same hardware.</li>
<li><strong>Cost</strong>: Reduced compute costs by 30%.</li>
</ul>
<p>This architecture became the standard for all real-time ML services in the company.</p>

    </div>
</section>


<section>
    <nav class="post-navigation">
        
        
        <div class="nav-next">
            <span class="nav-label">Siguiente →</span>
            <a href="/posts/segunda-entrada/">Building the MLOps Platform</a>
        </div>
        
    </nav>
</section>


    </main>

    
    <footer class="site-footer">
        <div class="stream-container">
            <p>&copy; 2025 Oscar Armas</p>
            
        </div>
    </footer>

    
    <script src="/js/main.js"></script>
</body>
</html>

